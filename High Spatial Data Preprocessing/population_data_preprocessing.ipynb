{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a809032",
   "metadata": {},
   "source": [
    "## Population Data Processing\n",
    "\n",
    "The population data for this study were collected from the Copernicus Emergency Management Service provided by the [GHSL - Global Human Settlement Layer](https://human-settlement.emergency.copernicus.eu/download.php?ds=pop)\n",
    "}. These data were gathered by downloading the tiles of TIFF files covering the areas near our study regions. These data have a resolution of 100m and consist of population estimates from the years 2000 to 2025, with intervals of five years (i.e., 2000, 2005, 2010, etc.)\n",
    "\n",
    "After downloading the tiles that cover our study areas, we used the country shapefiles to extract data aligning with the national boundaries of both Rwanda and Tanzania. To estimate population data for years not directly available (e.g., 2001, 2002, 2003, and 2004), we performed linear interpolation. This process involved reading existing TIFF files for known years, interpolating the data for the missing years, and generating new TIFF files. This method ensured accurate and reliable population estimates based on existing data, providing a continuous and consistent dataset for our analysis.\n",
    "\n",
    "After obtaining the TIFF files for each country, we used district shapefiles to extract the population data for each district and subsequently computed various metrics, including population density, Gini coefficient, and spatial autocorrelation at 2 km and 5 km scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b087ecc",
   "metadata": {},
   "source": [
    "## Computed Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac8bf5",
   "metadata": {},
   "source": [
    "1. Gini Entropy\n",
    "\n",
    "Gini entropy is a measure derived from the concept of Gini impurity used in decision trees, and it's related to the Gini coefficient used in economics to measure income inequality. In the context of population data, Gini entropy can be used to assess the inequality in the distribution of population across different areas. A higher Gini entropy indicates more uneven distribution, while a lower Gini entropy indicates a more even distribution.\n",
    "2. Autocorrelation (autocorr2 and autocorr5)\n",
    "\n",
    "Autocorrelation measures the correlation of a signal with a delayed copy of itself as a function of delay. In the context of spatial data like population density, autocorrelation at lag 2 (autocorr2) and lag 5 (autocorr5) can be used to understand the spatial correlation of population data over different distances. Positive autocorrelation means that high population densities are clustered together, while negative autocorrelation means that high and low population densities are interspersed.\n",
    "Why Use These Metrics?\n",
    "\n",
    "    Understanding Distribution: Gini entropy helps in understanding how evenly or unevenly the population is distributed across regions or districts. This can be crucial for resource allocation and policy-making.\n",
    "    Spatial Patterns: Autocorrelation helps in identifying spatial patterns and dependencies in the population data. It indicates whether population densities are clustered or dispersed over space.\n",
    "    Normalized Representation: While Gini entropy and autocorrelation do not normalize the data in the traditional sense, they help in normalizing the understanding of population distribution by providing standardized metrics that can be compared across different regions or time periods.\n",
    "\n",
    "Example Usage in Population Data Analysis\n",
    "\n",
    "In a typical population data analysis, these metrics can provide deeper insights:\n",
    "\n",
    "    Gini Entropy: To measure and compare the inequality of population distribution in different districts or regions.\n",
    "    Autocorr2 and Autocorr5: To analyze the spatial patterns of population density and identify whether population centers are clustering together or spreading out over space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c23f27",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0365b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.merge import merge\n",
    "import os\n",
    "import re\n",
    "import fiona\n",
    "from scipy.interpolate import interp1d\n",
    "import rasterio.features\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import mapping, shape\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ca224",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992df012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tiff_files(tiff_files, output_path):\n",
    "    \"\"\"\n",
    "    Merge multiple TIFF files into a single TIFF file.\n",
    "\n",
    "    Parameters:\n",
    "    tiff_files (list of str): List of file paths to the input TIFF files.\n",
    "    output_path (str): File path to save the merged output TIFF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the TIFF files\n",
    "        src_files_to_mosaic = []\n",
    "        for fp in tiff_files:\n",
    "            src = rasterio.open(fp)\n",
    "            src_files_to_mosaic.append(src)\n",
    "\n",
    "        # Merge the TIFF files\n",
    "        mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "        # Define the metadata for the output file\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_trans\n",
    "        })\n",
    "\n",
    "        # Write the merged TIFF file to disk\n",
    "        with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "\n",
    "        # Close all opened files\n",
    "        for src in src_files_to_mosaic:\n",
    "            src.close()\n",
    "\n",
    "        print(f\"Data has been successfully merged and is available at: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e626cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(tiff_path, shapefile_path, output_path):\n",
    "    \"\"\"\n",
    "    Extract data from a TIFF file using a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    tiff_path (str): File path to the input TIFF file.\n",
    "    shapefile_path (str): File path to the input shapefile.\n",
    "    output_path (str): File path to save the extracted data TIFF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the TIFF file to get the CRS\n",
    "        with rasterio.open(tiff_path) as src:\n",
    "            tiff_crs = src.crs\n",
    "\n",
    "        # Read and reproject the shapefile to match the TIFF file's CRS\n",
    "        shapefile = gpd.read_file(shapefile_path)\n",
    "        shapefile = shapefile.to_crs(tiff_crs)\n",
    "\n",
    "        # Get the geometry from the shapefile\n",
    "        geometries = [mapping(geom) for geom in shapefile.geometry]\n",
    "\n",
    "        # Open the TIFF file again to mask it with the reprojected shapefile geometries\n",
    "        with rasterio.open(tiff_path) as src:\n",
    "            out_image, out_transform = mask(src, geometries, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "            out_meta.update({\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "                \"crs\": tiff_crs\n",
    "            })\n",
    "\n",
    "        # Write the clipped TIFF file to disk\n",
    "        with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "        # Print success message with output path\n",
    "        print(f\"Data successfully extracted and saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026a2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_extraction(tiff_files, shapefile_path, output_directory, prefix):\n",
    "    \"\"\"\n",
    "    Process a list of TIFF files by extracting data using a shapefile and saving with a specified prefix.\n",
    "\n",
    "    Parameters:\n",
    "    tiff_files (list of str): List of file paths to the input TIFF files.\n",
    "    shapefile_path (str): File path to the input shapefile.\n",
    "    output_directory (str): Directory path to save the extracted data TIFF files.\n",
    "    prefix (str): Prefix to use for the output TIFF files.\n",
    "    \"\"\"\n",
    "    for tiff_path in tiff_files:\n",
    "        \n",
    "       # Generate the output file name and path\n",
    "        file_name = os.path.basename(tiff_path).replace('merged', 'data')\n",
    "        output_file_name = f\"{prefix}_{file_name}\"\n",
    "        output_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "        # Call the extract_data function\n",
    "        extract_data(tiff_path, shapefile_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "706560e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Normalize the Population\n",
    "''''\n",
    "def gini_entropy(data):\n",
    "    \"\"\"Compute the Gini entropy of a dataset.\"\"\"\n",
    "    if len(data) == 0:\n",
    "        return np.nan\n",
    "    scaled_data = minmax_scale(data, feature_range=(0, 1))\n",
    "    return entropy(scaled_data, base=2)\n",
    "'''\n",
    "def gini_coefficient(data):\n",
    "    \"\"\"Compute the Gini coefficient of a dataset.\"\"\"\n",
    "    if len(data) == 0:\n",
    "        return np.nan\n",
    "    data = np.sort(data)\n",
    "    n = len(data)\n",
    "    index = np.arange(1, n + 1)\n",
    "    gini_index = (2 * np.sum(index * data)) / (n * np.sum(data)) - (n + 1) / n\n",
    "    return gini_index\n",
    "\n",
    "def autocorr(x, lag):\n",
    "    \"\"\"Compute the autocorrelation of a dataset at a specified lag.\"\"\"\n",
    "    if len(x) < lag + 1:\n",
    "        return np.nan\n",
    "    return np.corrcoef(np.array([x[:-lag], x[lag:]]))[0, 1]\n",
    "\n",
    "def autocorr2(data):\n",
    "    \"\"\"Compute the autocorrelation at lag 2.\"\"\"\n",
    "    return autocorr(data, 2)\n",
    "\n",
    "def autocorr5(data):\n",
    "    \"\"\"Compute the autocorrelation at lag 5.\"\"\"\n",
    "    return autocorr(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "474a2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_district_population(tiff_path, shapefile_path, output_directory):\n",
    "    \"\"\"Extract and process population data from TIFF file.\"\"\"\n",
    "    try:\n",
    "        # Open the TIFF file to get the CRS and data\n",
    "        with rasterio.open(tiff_path) as src:\n",
    "            tiff_crs = src.crs\n",
    "\n",
    "            # Read and reproject the shapefile to match the TIFF file's CRS\n",
    "            shapefile = gpd.read_file(shapefile_path)\n",
    "            shapefile = shapefile.to_crs(tiff_crs)\n",
    "\n",
    "            results = []\n",
    "\n",
    "            # Process each district\n",
    "            for _, row in shapefile.iterrows():\n",
    "                geometry = [mapping(row['geometry'])]\n",
    "                region = row.get('region', row.get('province'))\n",
    "                district = row['district']\n",
    "\n",
    "                # Mask the TIFF file with the geometry\n",
    "                out_image, out_transform = mask(src, geometry, crop=True)\n",
    "                out_image = out_image[0]  # Extract the first layer if multi-dimensional\n",
    "                \n",
    "                # Sum only the valid pixel values\n",
    "                population = np.sum(out_image[out_image != src.nodata])\n",
    "                \n",
    "                # Handle potential scale factor (if the population density needs to be adjusted)\n",
    "                # Here we assume pixel values are the population counts directly\n",
    "                # If pixel values represent density or other metrics, apply appropriate scaling\n",
    "                \n",
    "                population_density = population / row['geometry'].area\n",
    "\n",
    "                # Flatten the masked image for metric calculations\n",
    "                flat_image = out_image.flatten()\n",
    "                flat_image = flat_image[np.isfinite(flat_image)]  # Exclude NaN and inf values\n",
    "                flat_image = flat_image[flat_image != src.nodata]  # Exclude no-data values\n",
    "\n",
    "                if flat_image.size == 0:\n",
    "                    continue  # Skip if no valid data\n",
    "\n",
    "                # Compute metrics (assuming functions gini_entropy, autocorr2, autocorr5 are defined)\n",
    "                gini = gini_coefficient(flat_image)\n",
    "                ac2 = autocorr2(flat_image)\n",
    "                ac5 = autocorr5(flat_image)\n",
    "\n",
    "                results.append({\n",
    "                    'year': re.search(r'(\\d{4})', tiff_path).group(1),\n",
    "                    'region': region,\n",
    "                    'district': district,\n",
    "                    'population': population,\n",
    "                    'population_density': population_density,\n",
    "                    'gini_coefficient': gini,\n",
    "                    'autocorr2': ac2,\n",
    "                    'autocorr5': ac5,\n",
    "                    'geometry': row['geometry']\n",
    "                })\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        # Save to CSV without geometry column\n",
    "        df_without_geometry = df.drop(columns=['geometry'])\n",
    "        year = re.search(r'(\\d{4})', tiff_path).group(1)\n",
    "        csv_path = os.path.join(output_directory, f\"{year}_population_data.csv\")\n",
    "        df_without_geometry.to_csv(csv_path, index=False)\n",
    "\n",
    "        # Save to GeoJSON with geometry column\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        geojson_path = os.path.join(output_directory, f\"{year}_population_data.geojson\")\n",
    "        gdf.to_file(geojson_path, driver='GeoJSON')\n",
    "\n",
    "        print(f\"The CSV file of population data is successfully extracted and saved to {csv_path}\")\n",
    "        print(f\"The geojson file of population data is successfully extracted and saved to {geojson_path}\")\n",
    "        return df_without_geometry\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88196812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract_district_population(tiff_paths, shapefile_path, output_directory, prefix):\n",
    "    \"\"\"Batch extract district population data from a list of TIFF files.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for tiff_path in tiff_paths:\n",
    "        extract_district_population(tiff_path, shapefile_path, output_directory)\n",
    "        year = re.search(r'(\\d{4})', tiff_path).group(1)\n",
    "        csv_path = os.path.join(output_directory, f\"{year}_population_data.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"Warning: CSV file {csv_path} not found, skipping.\")\n",
    "\n",
    "    # Merge all data into a single DataFrame\n",
    "    if all_data:\n",
    "        merged_df = pd.concat(all_data, ignore_index=True)\n",
    "        merged_csv_path = os.path.join(output_directory, f\"{prefix}_population_data.csv\")\n",
    "        merged_df.to_csv(merged_csv_path, index=False)\n",
    "        print(f\"All data successfully merged and saved to {merged_csv_path}\")\n",
    "        \n",
    "        # Save the merged data to an Excel file\n",
    "        merged_excel_path = os.path.join(output_directory, f\"{prefix}_population_data.xlsx\")\n",
    "        merged_df.to_excel(merged_excel_path, index=False)\n",
    "        print(f\"All data successfully merged and saved to {merged_excel_path}\")\n",
    "    else:\n",
    "        print(\"No data was processed. Please check the input TIFF files and shapefile.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de0aab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate_rasters(prefix,raster_paths, output_dir, target_years):\n",
    "    \"\"\"\n",
    "    Linearly interpolate rasters between given years using interp1d in a vectorized manner.\n",
    "\n",
    "    Parameters:\n",
    "    raster_paths (dict): A dictionary with years as keys and file paths of existing TIFF files as values.\n",
    "    output_dir (str): Directory to save the interpolated TIFF files.\n",
    "    target_years (list of int): List of specific target years for interpolation.\n",
    "    prefix (str): Prefix for the output file names.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with interpolated years as keys and interpolated rasters as values.\n",
    "    \"\"\"\n",
    "    known_years = sorted(raster_paths.keys())\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read the existing TIFF files\n",
    "    data_dict = {}\n",
    "    profile = None\n",
    "    for year in known_years:\n",
    "        with rasterio.open(raster_paths[year]) as src:\n",
    "            data_dict[year] = src.read(1)\n",
    "            if profile is None:\n",
    "                profile = src.profile\n",
    "\n",
    "    # Get the shape of the data\n",
    "    sample_year = known_years[0]\n",
    "    sample_data = data_dict[sample_year]\n",
    "    height, width = sample_data.shape\n",
    "\n",
    "    # Stack data into a single array for fitting\n",
    "    data = np.stack([data_dict[year] for year in known_years], axis=0)\n",
    "\n",
    "    # Define the years corresponding to your data\n",
    "    years = np.array(known_years)\n",
    "\n",
    "    # Reshape the data for vectorized interpolation\n",
    "    data_reshaped = data.reshape((len(known_years), -1))\n",
    "\n",
    "    # Initialize interpolated data array\n",
    "    interpolated_rasters = {}\n",
    "\n",
    "    # Create an interp1d object for vectorized interpolation\n",
    "    interpolator = interp1d(years, data_reshaped, kind='linear', axis=0, fill_value='extrapolate')\n",
    "\n",
    "    for target_year in target_years:\n",
    "        if target_year in known_years:\n",
    "            interpolated_rasters[target_year] = data_dict[target_year]\n",
    "            continue\n",
    "\n",
    "        # Perform vectorized interpolation\n",
    "        target_values = interpolator(target_year)\n",
    "\n",
    "        # Reshape the interpolated values back to the original shape\n",
    "        target_values = target_values.reshape((height, width))\n",
    "\n",
    "        interpolated_rasters[target_year] = target_values\n",
    "\n",
    "        # Write the interpolated raster to a new file\n",
    "        output_file = os.path.join(output_dir, f'{prefix}_{target_year}_population_data.tif')\n",
    "        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(target_values.astype(profile['dtype']), 1)  # Ensure dtype matches profile\n",
    "        print(f\"Generated {output_file} with interpolated population values.\")\n",
    "\n",
    "    print(\"Interpolation and TIFF file generation completed successfully.\")\n",
    "    #return interpolated_rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590c180",
   "metadata": {},
   "source": [
    "### Merge The Tiff File of Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "591d5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2000\n",
    "t1 = 'population_data/2000/1.tif'\n",
    "t2 = 'population_data/2000/2.tif'\n",
    "t3 = 'population_data/2000/3.tif'\n",
    "t4 = 'population_data/2000/4.tif'\n",
    "t5 = 'population_data/2000/5.tif'\n",
    "t6 = 'population_data/2000/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2000_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c215cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2005\n",
    "t1 = 'population_data/2005/1.tif'\n",
    "t2 = 'population_data/2005/2.tif'\n",
    "t3 = 'population_data/2005/3.tif'\n",
    "t4 = 'population_data/2005/4.tif'\n",
    "t5 = 'population_data/2005/5.tif'\n",
    "t6 = 'population_data/2005/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2005_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ca1cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2010\n",
    "t1 = 'population_data/2010/1.tif'\n",
    "t2 = 'population_data/2010/2.tif'\n",
    "t3 = 'population_data/2010/3.tif'\n",
    "t4 = 'population_data/2010/4.tif'\n",
    "t5 = 'population_data/2010/5.tif'\n",
    "t6 = 'population_data/2010/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2010_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f2f1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2015\n",
    "t1 = 'population_data/2015/1.tif'\n",
    "t2 = 'population_data/2015/2.tif'\n",
    "t3 = 'population_data/2015/3.tif'\n",
    "t4 = 'population_data/2015/4.tif'\n",
    "t5 = 'population_data/2015/5.tif'\n",
    "t6 = 'population_data/2015/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2015_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fac1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2020\n",
    "t1 = 'population_data/2020/1.tif'\n",
    "t2 = 'population_data/2020/2.tif'\n",
    "t3 = 'population_data/2020/3.tif'\n",
    "t4 = 'population_data/2020/4.tif'\n",
    "t5 = 'population_data/2020/5.tif'\n",
    "t6 = 'population_data/2020/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2020_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f10b476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the population data of 2025\n",
    "t1 = 'population_data/2025/1.tif'\n",
    "t2 = 'population_data/2025/2.tif'\n",
    "t3 = 'population_data/2025/3.tif'\n",
    "t4 = 'population_data/2025/4.tif'\n",
    "t5 = 'population_data/2025/5.tif'\n",
    "t6 = 'population_data/2025/6.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "output_path = 'population_data/2025_population_merged.tif'\n",
    "#merge_tiff_files(tiff_files, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bd8b9",
   "metadata": {},
   "source": [
    "## Extract The Population Data  For Tanzania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cd28b",
   "metadata": {},
   "source": [
    "#### Get the Tiff file of Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da183d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_dir = 'tanzania_data/'\n",
    "prefix = 'tz'\n",
    "shapefile_path = tz_dir + 'shapefiles/tz_country.shp'\n",
    "output_directory = tz_dir + 'population_data/'\n",
    "t1 = 'population_data/2000_population_merged.tif'\n",
    "t2 = 'population_data/2005_population_merged.tif'\n",
    "t3 = 'population_data/2010_population_merged.tif'\n",
    "t4 = 'population_data/2015_population_merged.tif'\n",
    "t5 = 'population_data/2020_population_merged.tif'\n",
    "t6 = 'population_data/2025_population_merged.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "#batch_data_extraction(tiff_files, shapefile_path, output_directory, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255926b",
   "metadata": {},
   "source": [
    "#### Interpolate the Missing Year of Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc3fbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'tz'\n",
    "output_dir = tz_dir + 'population_data/interpolated/'\n",
    "t1 = tz_dir + 'population_data/tz_2000_population_data.tif'\n",
    "t2 = tz_dir + 'population_data/tz_2005_population_data.tif'\n",
    "t3 = tz_dir + 'population_data/tz_2010_population_data.tif'\n",
    "t4 = tz_dir + 'population_data/tz_2015_population_data.tif'\n",
    "t5 = tz_dir + 'population_data/tz_2020_population_data.tif'\n",
    "t6 = tz_dir + 'population_data/tz_2025_population_data.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0bf9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2010: t3,\n",
    "    2015: t4\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2011, 2012, 2013, 2014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bda38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2015: t4,\n",
    "    2020: t5\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2016, 2017, 2018, 2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b223e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2020: t5,\n",
    "    2025: t6\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2021, 2022, 2023, 2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b56e0",
   "metadata": {},
   "source": [
    "#### Extract The Population Data of of Each Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7008b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'tz'\n",
    "shapefile_path = tz_dir + 'shapefiles/tz_districts.shp'\n",
    "output_directory = tz_dir + 'population_data/processed/'\n",
    "t1 = tz_dir + 'population_data/tz_2010_population_data.tif'\n",
    "t2 = tz_dir + 'population_data/interpolated/tz_2011_population_data.tif'\n",
    "t3 = tz_dir + 'population_data/interpolated/tz_2012_population_data.tif'\n",
    "t4 = tz_dir + 'population_data/interpolated/tz_2013_population_data.tif'\n",
    "t5 = tz_dir + 'population_data/interpolated/tz_2014_population_data.tif'\n",
    "t6 = tz_dir + 'population_data/tz_2015_population_data.tif'\n",
    "t7 = tz_dir + 'population_data/interpolated/tz_2016_population_data.tif'\n",
    "t8 = tz_dir + 'population_data/interpolated/tz_2017_population_data.tif'\n",
    "t9 = tz_dir + 'population_data/interpolated/tz_2018_population_data.tif'\n",
    "t10 = tz_dir + 'population_data/interpolated/tz_2019_population_data.tif'\n",
    "t11 = tz_dir + 'population_data/tz_2020_population_data.tif'\n",
    "t12 = tz_dir + 'population_data/interpolated/tz_2021_population_data.tif'\n",
    "t13 = tz_dir + 'population_data/interpolated/tz_2022_population_data.tif'\n",
    "t14 = tz_dir + 'population_data/interpolated/tz_2023_population_data.tif'\n",
    "\n",
    "tiff_paths = [t1, t2, t3, t4, t5, t6, t7,\n",
    "              t8, t9, t10, t11, t12, t13, t14\n",
    "             ]\n",
    "\n",
    "#extract_district_population(tiff_path, shapefile_path, output_directory)\n",
    "#batch_extract_district_population(tiff_paths, shapefile_path, output_directory, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be463599",
   "metadata": {},
   "source": [
    "## Extract The Population Data  For Rwanda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cde23",
   "metadata": {},
   "source": [
    "#### Get the Tiff file of Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2313944",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_dir = 'rwanda_data/'\n",
    "prefix = 'rw'\n",
    "shapefile_path = rw_dir + 'shapefiles/rw_country.shp'\n",
    "output_directory = rw_dir + 'population_data/'\n",
    "t1 = 'population_data/2000_population_merged.tif'\n",
    "t2 = 'population_data/2005_population_merged.tif'\n",
    "t3 = 'population_data/2010_population_merged.tif'\n",
    "t4 = 'population_data/2015_population_merged.tif'\n",
    "t5 = 'population_data/2020_population_merged.tif'\n",
    "t6 = 'population_data/2025_population_merged.tif'\n",
    "tiff_files = [t1, t2, t3, t4, t5, t6]\n",
    "#batch_data_extraction(tiff_files, shapefile_path, output_directory, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad6f9f",
   "metadata": {},
   "source": [
    "#### Interpolate the Missing Year of Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7086911",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'rw'\n",
    "shapefile_path = rw_dir + 'shapefiles/rw_district.shp'\n",
    "output_dir = rw_dir + 'population_data/interpolated/'\n",
    "t1 = rw_dir + 'population_data/rw_2000_population_data.tif'\n",
    "t2 = rw_dir + 'population_data/rw_2005_population_data.tif'\n",
    "t3 = rw_dir + 'population_data/rw_2010_population_data.tif'\n",
    "t4 = rw_dir + 'population_data/rw_2015_population_data.tif'\n",
    "t5 = rw_dir + 'population_data/rw_2020_population_data.tif'\n",
    "t6 = rw_dir + 'population_data/rw_2025_population_data.tif'\n",
    "tiff_paths = [t1, t2, t3, t4, t5, t6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ddcd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2005: t2,\n",
    "    2010: t3\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2006, 2007, 2008, 2009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f77f9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2010: t3,\n",
    "    2015: t4\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2011, 2012, 2013, 2014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e53a10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2015: t4,\n",
    "    2020: t5\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2016, 2017, 2018, 2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5c7f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tif_paths = {\n",
    "    2020: t5,\n",
    "    2025: t6\n",
    "}\n",
    "\n",
    "#linear_interpolate_rasters(prefix,tif_paths, output_dir, target_years= [2021, 2022, 2023, 2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44678cd4",
   "metadata": {},
   "source": [
    "#### Extract The Population Data of of Each Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e00242dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'rw'\n",
    "shapefile_path = rw_dir + 'shapefiles/rw_district.shp'\n",
    "output_directory = rw_dir + 'population_data/processed/'\n",
    "t1 = rw_dir + 'population_data/rw_2005_population_data.tif'\n",
    "t2 = rw_dir + 'population_data/interpolated/rw_2006_population_data.tif'\n",
    "t3 = rw_dir + 'population_data/interpolated/rw_2007_population_data.tif'\n",
    "t4 = rw_dir + 'population_data/interpolated/rw_2008_population_data.tif'\n",
    "t5 = rw_dir + 'population_data/interpolated/rw_2009_population_data.tif'\n",
    "t6 = rw_dir + 'population_data/rw_2010_population_data.tif'\n",
    "t7 = rw_dir + 'population_data/interpolated/rw_2011_population_data.tif'\n",
    "t8 = rw_dir + 'population_data/interpolated/rw_2012_population_data.tif'\n",
    "t9 = rw_dir + 'population_data/interpolated/rw_2013_population_data.tif'\n",
    "t10 = rw_dir + 'population_data/interpolated/rw_2014_population_data.tif'\n",
    "t11 = rw_dir + 'population_data/rw_2015_population_data.tif'\n",
    "t12 = rw_dir + 'population_data/interpolated/rw_2016_population_data.tif'\n",
    "t13 = rw_dir + 'population_data/interpolated/rw_2017_population_data.tif'\n",
    "t14 = rw_dir + 'population_data/interpolated/rw_2018_population_data.tif'\n",
    "t15 = rw_dir + 'population_data/interpolated/rw_2019_population_data.tif'\n",
    "t16 = rw_dir + 'population_data/rw_2020_population_data.tif'\n",
    "t17 = rw_dir + 'population_data/interpolated/rw_2021_population_data.tif'\n",
    "t18 = rw_dir + 'population_data/interpolated/rw_2022_population_data.tif'\n",
    "tiff_paths = [t1, t2, t3, t4, t5, t6, t7, t8, t9, t10, t11, t12, t13, t14, t15, t16, t17, t18]\n",
    "\n",
    "#batch_extract_district_population(tiff_paths, shapefile_path, output_directory, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b19b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
